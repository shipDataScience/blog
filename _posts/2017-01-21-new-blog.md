---
layout: post
title: INCEPTION - Why start Ship Data Science? 
---

Welcome to the first blog post ever for my project, Ship Data Science.

Let's kick things off by considering a question so antagonizing 
that you might be tempted to browse away.

A question that over the last ten years has raised and destroyed global companies, 
altered the political landscape of the USA, and lead to lifesaving inventions and occasional deaths.

*Do you think a machine could do a better job running your business than you?*

Over the early 2000's, some companies that asked that question created **massive business empires** by turning
over evermore small, bite-size but high-impact pieces of strategy to machine learning algorithms. 
Did you miss it? Check out some examples:

  - Capital One built the first profitable subprime credit card markets from 'information based strategy';
    a process of data-driven learning that culminated in one of the industry's most profitable credit businesses,
    and powerful automated models to drive lending decisioning and valuation for the business.
  - Google turned internet search results over to an increasingly-advanced series of search algorithms,
    starting with the humble but revolutionary pagerank and diversifying into intention-detection algorithms. The massive
    quality increase resulted in winning the lion's share of the $10bn++ search advertising market.
  - LinkedIn rolled out a recommendations product suggesting users connect with people they may know, resulting in an 
    step-change in the connection, engagement, and popularity of their site during the critical early growth period of the company.
  - Netflix built recommendation algorithms so powerful they are able to roll the algorithm's input forward into
    content acquisition planning, even having computers help evaluate show pilot's.

There have been many examples too of overreach---catastrophes from trusting machines to manage too much.

  - Hillary Clinton's campaign trusted election models predicting a large margin of victory and a 'firewall' in 
    key swing states that evaporated over the last months of the election as she directed efforts elsewhere.
  - Mortgage default models built prior to 2007 had never seen data from markets where house prices fell dramatically---
    an effect that turned out to step-change defaults due to mortgages going 'underwater'--- 
    removing the easy out for homeowners to simply sell an appreciating home for a higher value 
    and exit the mortgage when payments got too expensive. This fundamental misvaluation of 
    mortgage loans was a key contributor to the 2007 market crash, ultimately wiping out trillions
    in consumer wealth.
  - It's not uncommon for startups building recommendation products to accidentally flip the sign on the recommender scores 
    due to engineering error, resulting in 'anti-recommenders' that crater customer conversion.
  - Tragically, self-driving car technology is not perfect, and there have already been human casualties from 
    preventable algorithmic mistakes on the road.

So where do you fall? Do you chase the upside from bringing automated decisioning to your products,
or avoid the risk? 

Historically, either-or has been by far the most common example. It's challenging to manage machines;
you can't ask them questions, and instead have to watch what they do on thousands
or millions of decisions a day and draw conclusions yourself on questions like these:

  - Is my model facing a changing or stable world?
  - Are the relationships my model depends on breaking down?
  - Is the model still predicting well?
  - Are new areas of opportunity emerging?

Answering these questions in the past has been a deep-dive analysis that generally runs 
a few times a year and requires extensive involvement from specialized data scientists. 
This is cost prohibitive and hard to translate into a concise message---leading to 
an industry landscape where data scientists are trusted to create and manage their own
black-box organizations. Most models go unmanaged and disaster can happen any time.

However, the techniques that are used to determine if models are working or breaking down
are portable across most modeling applications; creating the classic value proposition for 
a platform---one global, trusted implementation for the metrics that really matter, and 
significantly reduced speed to market and costs compared to ad hoc efforts. Not to mention
badge-ified, easy-to-understand status reports that can alert and justify events.

That's Ship Data Science --- the model monitoring platform. Just connect your project, register a data source, and 
enjoy continuous model monitoring and alerts. [Get in touch](mailto:info@shipdatascience.com)!


